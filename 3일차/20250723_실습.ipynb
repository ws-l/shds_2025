{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jY7nrX72uwOl"
      },
      "outputs": [],
      "source": [
        "#creditApprovalUCI -> dropna - > 범주형컬럼만 선택\n",
        "import pandas as pd\n",
        "\n",
        "credit = pd.read_csv('creditApprovalUCI.csv')\n",
        "credit.dropna(inplace=True)\n",
        "credit.select_dtypes(include='object').A1.replace(['b','a'],[0,1])\n",
        "tmp = credit.select_dtypes(include='object').A1\n",
        "pd.get_dummies(tmp).astype(\"int\")      #One Hot Encoding, OHE\n",
        "pd.get_dummies(credit)\n",
        "\n",
        "#credit에서 범주형변수들을 OHE -> 1, 0으로 바꾸시고, 기존 수치형 변수랑 합쳐보세요.\n",
        "tmp1 = pd.get_dummies( credit.select_dtypes(include='object')).astype(\"int\")\n",
        "tmp2 = credit.select_dtypes(exclude='object')\n",
        "pd.concat([tmp1, tmp2], axis=1)\n",
        "\n",
        "pd.get_dummies(credit.A5, drop_first=True)\n",
        "\n",
        "tmp3 = pd.get_dummies(credit.A6)\n",
        "import numpy as np\n",
        "np.argmax( tmp3, axis=1 )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip mortDefault.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gX6LsU-v95Ok",
        "outputId": "b0aaaaf3-c888-47ea-bc25-e43ade9803bf"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  mortDefault.zip\n",
            "  inflating: mortDefault2007.csv     \n",
            "  inflating: mortDefault2008.csv     \n",
            "  inflating: mortDefault2009.csv     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#diabetes.csv를 Outcome1,0일때의 변수 평균\n",
        "#파티셔닝->train->smote(필요시), DT로 모델링 -> test로 평가\n",
        "from imblearn.over_sampling import SMOTE\n",
        "df = pd.read_csv(\"mortDefault2009.csv\")"
      ],
      "metadata": {
        "id": "xsN0ZyMRVaPb"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(\"year\", axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "cz_iW21o94d2"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.concat([df.query( \"default==1\"), df.query( \"default==0\").sample(24741)])"
      ],
      "metadata": {
        "id": "IM3piUNb-aoK"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df2.drop(\"default\", axis=1), df2[\"default\"], test_size=0.2, random_state=42)\n",
        "X_train_res, y_train_res = SMOTE(sampling_strategy=\"auto\",k_neighbors=5).fit_resample( X_train, y_train  )"
      ],
      "metadata": {
        "id": "uyQEmY4O1wPb"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "dt = DecisionTreeClassifier(max_depth=100)\n",
        "dt.fit(X_train_res, y_train_res)  #dt.feature_importances_\n",
        "rf = RandomForestClassifier( max_depth=100)\n",
        "rf.fit(X_train_res, y_train_res)\n",
        "ab = AdaBoostClassifier()\n",
        "ab.fit(X_train_res, y_train_res)\n"
      ],
      "metadata": {
        "id": "469yDXI36tCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#secom.zip의 secom가 X변수들, secom_label y변수, 시간정보->datetime\n",
        "#X변수들의 이름  X1, X2, .....\n",
        "#  [ 'X' +str(i) for i in range(변수개수)]\n",
        "#y변수 이름 y\n",
        "#y -1, 1  -> 0, 1\n",
        "#파티셔닝, DT, RF, GB으로 모델링 (GB는 GridSearch)\n",
        "!unzip secom.zip"
      ],
      "metadata": {
        "id": "TfrcN3qtGVlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.read_csv(\"secom.data\", sep=\" \", header=None)\n",
        "X.columns =  [ 'X' +str(i+1) for i in range(590)]\n",
        "y = pd.read_csv(\"secom_labels.data\", sep=\" \", header=None)\n",
        "y.columns = [\"y\", \"date\"]\n",
        "y[\"y\"].replace({-1:0, 1:1}, inplace=True)\n",
        "y[\"date\"] = pd.to_datetime(y[\"date\"])\n",
        "df = pd.concat( [X, y], axis=1)"
      ],
      "metadata": {
        "id": "s1wAI27yIT0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = df.isnull().mean().sort_values(ascending=False)\n",
        "cols = tmp[tmp<0.05].index.tolist()\n",
        "df2 = df[ cols]\n",
        "df2.dropna(inplace=True)\n",
        "df2.drop(\"date\", axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "q5FkkFokK_Mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(df2.drop(\"y\", axis=1), df2[\"y\"], test_size=0.1,\n",
        "                                               random_state=42, stratify = df2[\"y\"])"
      ],
      "metadata": {
        "id": "6LZD5Gb0J-G-"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gb = GradientBoostingClassifier()\n",
        "gb.fit(X_train, y_train)\n",
        "print( classification_report(y_test, gb.predict(X_test) ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtNGj8eX74D9",
        "outputId": "7363e367-0123-432a-8924-ccdf63048735"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.97      0.95       130\n",
            "           1       0.00      0.00      0.00        10\n",
            "\n",
            "    accuracy                           0.90       140\n",
            "   macro avg       0.46      0.48      0.47       140\n",
            "weighted avg       0.86      0.90      0.88       140\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZmF23RH0JsIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame( {\"cols\": df.drop(\"Outcome\", axis=1).columns,\n",
        "               \"imp\": rf.feature_importances_}).sort_values(\"imp\", ascending=False).head()"
      ],
      "metadata": {
        "id": "_2NUr5T8XM6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GridSearchCV   max_depth: 5, 10, 15, cv:5\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "gs = GridSearchCV( estimator=dt, param_grid={\"max_depth\":[5,10,15]}, cv=5)\n",
        "gs.fit(X_train_res, y_train_res)\n",
        "gs.best_params_\n",
        "dt2 = gs.best_estimator_"
      ],
      "metadata": {
        "id": "tJSJNCuUSkD5"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "y_hat = dt.predict( X_test)#dt.predict_proba( X_test) #dt.score( X_test, y_test)\n",
        "print( classification_report(y_test,y_hat ) )    #confusion_matrix(y_test, y_hat)"
      ],
      "metadata": {
        "id": "lqTE-GIcEJ7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "y_hat = rf.predict( X_test)#dt.predict_proba( X_test) #dt.score( X_test, y_test)\n",
        "print( classification_report(y_test,y_hat ) )    #confusion_matrix(y_test, y_hat)"
      ],
      "metadata": {
        "id": "fNer0aAMu-rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "y_hat = ab.predict( X_test)#dt.predict_proba( X_test) #dt.score( X_test, y_test)\n",
        "print( classification_report(y_test,y_hat ) )    #confusion_matrix(y_test, y_hat)"
      ],
      "metadata": {
        "id": "E4seDPb97gei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "y_hat = gb.predict( X_test)#dt.predict_proba( X_test) #dt.score( X_test, y_test)\n",
        "print( classification_report(y_test,y_hat ) )    #confusion_matrix(y_test, y_hat)"
      ],
      "metadata": {
        "id": "6J6QR9yC_rqX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}